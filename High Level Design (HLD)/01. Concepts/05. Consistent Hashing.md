# 🧭 **Consistent Hashing**

Consistent Hashing is a **load balancing and partitioning strategy** that minimizes reorganization when nodes are added or removed. It’s widely used in **distributed systems** for **sharding, caching, and routing requests** efficiently.

---

## 1. 🧠 What It Is

Consistent Hashing maps both **nodes (servers)** and **keys (data)** to the same circular hash space. Keys are assigned to the **next node in a clockwise direction**. When nodes are added/removed, **only a small portion** of keys need to be remapped.

---

## 2. ✅ Benefits

- 🚫 **Minimal disruption** when scaling nodes.
- 🧩 Works well in **distributed cache systems** (e.g., Memcached, Redis).
- 📦 Keeps **load evenly distributed**.
- 📊 Perfect for **sharded databases**, **distributed file systems**, and **message brokers**.

---

## 3. ⚠️ Drawbacks

- Needs **virtual nodes** for even load balancing.
- Slightly more **complex to implement**.
- Requires good **hash function** to avoid clustering.

---

## 4. 🔄 Real-World Usage

| System           | Use Case                       |
| ---------------- | ------------------------------ |
| Amazon Dynamo    | Partitioning + replication     |
| Apache Cassandra | Token ring + partition key     |
| Discord          | User sharding in backend infra |
| Netflix EVCache  | Cache key distribution         |

---

## 5. 🔬 How It Works

1. **Hash Space**: Imagine a circle from `0` to `2³² - 1`.
2. **Hash Nodes**: Each node is hashed into a point on the circle.
3. **Hash Keys**: Each key is hashed the same way.
4. **Routing Rule**: Each key goes to the first node **clockwise**.

### Diagram (Conceptual)

```
    [Node A] ----> [Node B] ----> [Node C]
        ^               ^              ^
      key1            key2           key3
```

If Node B is removed, only key2 is remapped to Node C — others are untouched.

---

## 6. 💡 Code Example — Basic Python Implementation

```python
import hashlib
import bisect

def hash_key(key):
    return int(hashlib.md5(key.encode()).hexdigest(), 16)

class ConsistentHashRing:
    def __init__(self, nodes=None, replicas=3):
        self.replicas = replicas
        self.ring = dict()
        self.sorted_keys = []

        if nodes:
            for node in nodes:
                self.add_node(node)

    def add_node(self, node):
        for i in range(self.replicas):
            virtual_node = f"{node}:{i}"
            key = hash_key(virtual_node)
            self.ring[key] = node
            bisect.insort(self.sorted_keys, key)

    def remove_node(self, node):
        for i in range(self.replicas):
            virtual_node = f"{node}:{i}"
            key = hash_key(virtual_node)
            self.ring.pop(key)
            self.sorted_keys.remove(key)

    def get_node(self, key_str):
        key = hash_key(key_str)
        index = bisect.bisect(self.sorted_keys, key) % len(self.sorted_keys)
        return self.ring[self.sorted_keys[index]]

# 🧪 Usage Example
nodes = ['cacheA', 'cacheB', 'cacheC']
ring = ConsistentHashRing(nodes)

print(ring.get_node('user123'))  # Might return 'cacheB'
print(ring.get_node('user456'))  # Might return 'cacheC'
```

---

## 7. ⚙️ Advanced Usage with Virtual Nodes

**Virtual nodes (vnodes)** are replicas of physical nodes placed at different positions in the hash ring. They improve **distribution balance**.

```python
# Already implemented above using `replicas=3`
ring = ConsistentHashRing(['db1', 'db2', 'db3'], replicas=100)
```

---

## 8. 🏗️ Real-World Example

### 🔄 WhatsApp Message Queue Partitioning

WhatsApp might hash a phone number:

```text
hash("+1-222-333-4444") % N_PARTITIONS
```

This directs the message to a specific queue partition using consistent hashing to avoid excessive remapping during scale events.

---

## 9. 🛠 Libraries & Tools

| Language | Library/Tool                                  |
| -------- | --------------------------------------------- |
| Python   | `hash_ring`, `ketama`, `pyconsistenthash`     |
| Java     | Used internally in Cassandra, Hazelcast       |
| Go       | `consistenthash` in `groupcache`              |
| Redis    | Cluster mode uses hash slots with consistency |

---

## 10. 🧠 Summary Table

| Principle          | Key Benefit                  | Example                             |
| ------------------ | ---------------------------- | ----------------------------------- |
| Consistent Hashing | Low remapping on node change | Redis Cluster with 16384 hash slots |
| Virtual Nodes      | Load balancing               | 100 replicas per physical node      |
| Hash Ring          | Even key distribution        | Cassandra, Dynamo                   |

---

## 🔚 Final Takeaways

- **Consistent Hashing** is essential for **distributed caching and sharding**.
- It ensures **minimal rehashing** as nodes are added/removed — crucial for dynamic, elastic systems.
- For production-grade systems, use libraries that support **virtual nodes, health checks, and rebalancing**.
- Combine with **load balancing and partition-aware routing** for best results.

---
