# üß† **Distributed Caching**

## üìñ What It Is:

**Distributed caching** refers to a caching system that **spans multiple nodes or machines**. It stores and manages frequently accessed data **across a network**, allowing large-scale applications to serve requests faster without overwhelming their databases or APIs.

Unlike in-memory caches like `localStorage` or `in-process` caches (e.g., `Guava Cache` in Java), distributed caches are **shared** and **centralized across systems** ‚Äî ideal for **horizontal scaling** and **stateless microservices**.

---

## üß± Why Use Distributed Caching?

| üèÅ Problem                            | üß† How Distributed Caching Helps                  |
| ------------------------------------- | ------------------------------------------------- |
| DB is overloaded with read requests   | Offloads to fast cache (e.g., Redis, Memcached)   |
| Multiple app instances need same data | Ensures consistency across services               |
| Stateless microservices architecture  | Stores session/config/state data centrally        |
| Global app ‚Üí needs fast local access  | Distributed caches support replication + sharding |

---

## üåç Architecture Diagram

```
           +--------------------+
           |    Application 1   |
           +--------------------+
                   |
           +--------------------+
           |    Application 2   |
           +--------------------+
                   |
          +------------------------+
          |   Distributed Cache    |  ‚áÑ  [Data Store]
          | (Redis/Memcached/etc) |
          +------------------------+
                   ‚Üë
          Multiple nodes/shards/replicas
```

---

## üöÄ Key Features of Distributed Caches

| Feature                    | Description                                 |
| -------------------------- | ------------------------------------------- |
| **Networked**              | Cache is accessed over TCP (vs in-process)  |
| **Scalable**               | Can be horizontally scaled (add nodes)      |
| **Sharded/Partitioned**    | Data split across multiple nodes            |
| **Replicated**             | Data can be mirrored for HA/fault tolerance |
| **Eviction/TTL**           | Auto-cleaning using LRU, LFU, TTL           |
| **Persistence (optional)** | Can optionally store cache to disk          |

---

## üß∞ Popular Distributed Cache Systems

| Tool      | Language | Strengths                              | Used By                  |
| --------- | -------- | -------------------------------------- | ------------------------ |
| Redis     | C        | Rich data types, persistence, pub/sub  | Twitter, GitHub, Shopify |
| Memcached | C        | Extremely fast, simple key-value store | Facebook, YouTube        |
| Hazelcast | Java     | In-memory data grid                    | Deutsche Bank, HP        |
| Couchbase | C++      | Built-in NoSQL + cache layer           | LinkedIn, SyncGateway    |
| Aerospike | C        | Flash-optimized, high-performance      | PayPal, AppNexus         |

---

## üß† Distributed Cache Concepts

### 1. üîÄ **Sharding (Partitioning)**

- Keys are distributed across multiple cache nodes using **consistent hashing** or modulo (`key % n`).
- Avoids overload of a single cache instance.

```plaintext
user:1001 ‚Üí Node A
user:1002 ‚Üí Node B
```

### 2. ‚ôªÔ∏è **Replication**

- Copies of the same cache data exist on multiple nodes for **failover and durability**.
- Typically **Master-Slave** or **Active-Active** configurations.

### 3. üîÅ **Eviction Policies**

- LRU (Least Recently Used)
- LFU (Least Frequently Used)
- TTL-based expiry (e.g., `set key value EX 60` in Redis)

### 4. üìä **Consistency**

| Model                | Description                                  |
| -------------------- | -------------------------------------------- |
| **Strong**           | Writes instantly visible across nodes (rare) |
| **Eventual**         | Most caches use this ‚Äî some delay            |
| **Read-Your-Writes** | Node-local consistency                       |

---

## üß™ Example: Redis Cluster (Python + redis-py)

```python
from rediscluster import RedisCluster

rc = RedisCluster(startup_nodes=[{"host": "127.0.0.1", "port": "7000"}], decode_responses=True)

# Write to cluster
rc.set("user:1234", "Alice", ex=3600)

# Read from cluster
name = rc.get("user:1234")
print(name)
```

Redis Cluster automatically handles **sharding, replication, and failover**.

---

## üí• When Distributed Cache Fails

### ‚ùå SPOF (Single Point of Failure):

- Solution: Use **replication**, **sentinel** (for Redis), or managed services (AWS ElastiCache)

### ‚ùå Cache Inconsistency:

- Use TTL + write-through/write-behind strategies

### ‚ùå Cache Stampedes:

- Use mutex locks (`SETNX`), **refresh-ahead**, or **staggered TTLs**

---

## üß≠ Real-World Use Cases

| Company | Cache System        | Use Case                                       |
| ------- | ------------------- | ---------------------------------------------- |
| Twitter | Redis               | Timelines, mentions                            |
| GitHub  | Memcached           | Repository metadata                            |
| Netflix | EVCache (Memcached) | User preferences, personalized recommendations |
| Uber    | Redis               | Geo-location caching, user sessions            |
| Airbnb  | Redis               | Availability calendars, pricing cache          |

---

## üß† Best Practices for Distributed Caching

1. **Set TTLs**: Never allow infinite cache unless intentional (e.g., config).
2. **Use namespacing**: Prevent key collision in multi-service architecture (`service:user:123`)
3. **Choose eviction wisely**: LRU for general, TTL for freshness, LFU for popularity
4. **Avoid large values**: Use cache for small, hot items (<1MB ideally)
5. **Test failover**: Simulate node crashes in staging
6. **Monitor hit ratio**: Track `hits / (hits + misses)` and alert if below threshold

---

## üìã Summary Table

| Topic       | Description                        | Notes                         |
| ----------- | ---------------------------------- | ----------------------------- |
| Sharding    | Split keys across nodes            | Use consistent hashing        |
| Replication | Mirror keys to other nodes         | Prevent data loss             |
| Eviction    | Auto-remove based on usage or time | LRU, TTL, LFU                 |
| Consistency | Guarantees of up-to-date values    | Most are eventual             |
| Persistence | Backup to disk                     | Optional in Redis             |
| Failover    | Auto-switch to replica             | Sentinel/Cluster mode         |
| Scalability | Add nodes without app change       | Redis Cluster, Memcached ring |

---

## üîö Final Takeaways

- Distributed caching enables **speed and scalability** across services.
- Combine with smart **caching strategies** (Cache-Aside, Write-Behind, etc.) for reliability.
- Choose **Redis** for versatility, **Memcached** for pure speed.
- **Consistency, Eviction, and Monitoring** are pillars of a production-ready setup.
- Think of distributed cache as **shared memory for your microservices**.

---
