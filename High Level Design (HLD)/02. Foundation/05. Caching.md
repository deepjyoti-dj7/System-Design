# ‚ö° **Caching**

Caching is a **performance optimization strategy** that stores frequently accessed data in **fast, temporary storage (RAM, SSD)** to reduce latency, database load, and computation time.

In **scalable system design**, caching is essential for **speed, cost efficiency**, and **availability under high load**. Major systems like **Facebook, Twitter, Amazon, and Google** rely heavily on multi-layered caching.

---

## üìñ Caching: Core Theory

### What Is Caching?

> Caching stores **expensive-to-retrieve data** in a faster, closer medium to avoid recomputation or re-fetching.

| Source                | Cached To      | Speed Gain    |
| --------------------- | -------------- | ------------- |
| Database (PostgreSQL) | Redis (RAM)    | \~10x to 100x |
| Backend computation   | Local memory   | \~100x        |
| Static assets (S3)    | CDN Edge Cache | \~10x         |

---

## üö¶ Where Caching Fits in Architecture

```
[User] ‚Üí [CDN] ‚Üí [Web Server] ‚Üí [Redis Cache] ‚Üí [Database]
                              ‚Ü≥ [In-Memory App Cache]
```

---

## üì¶ Types of Caches in System Design

| Type               | Scope                         | Examples                       |
| ------------------ | ----------------------------- | ------------------------------ |
| **Browser Cache**  | Local to user's browser       | JS, CSS, HTML caching          |
| **CDN Cache**      | Edge locations globally       | Cloudflare, CloudFront         |
| **App-Level**      | In-process memory (e.g., LRU) | Local function or object cache |
| **Distributed**    | Shared network cache          | Redis, Memcached               |
| **DB Query Cache** | Caches result sets            | MySQL Query Cache (deprecated) |

---

## üß† When to Use Caching

| Use Case                       | Cache Strategy                   |
| ------------------------------ | -------------------------------- |
| Frequent reads, rare writes    | Long TTL Redis cache             |
| Expensive computation (AI, ML) | In-memory app cache              |
| Static media delivery          | CDN edge caching                 |
| API rate limits or metadata    | Redis or in-memory counter       |
| Session management             | Redis or Memcached session store |

---

## üõ† Example: Redis Caching in a Flask App

```python
from flask import Flask
import redis

cache = redis.Redis(host='localhost', port=6379)

app = Flask(__name__)

@app.route('/expensive')
def expensive_operation():
    if (val := cache.get('expensive_result')):
        return val.decode()

    result = heavy_computation()
    cache.setex('expensive_result', 3600, result)  # TTL = 1 hr
    return result
```

---

## üìä Cache Invalidation Strategies

| Strategy               | Description                               | When to Use                           |
| ---------------------- | ----------------------------------------- | ------------------------------------- |
| **Time-based (TTL)**   | Auto-expiry after a period (e.g., 5 mins) | For moderately dynamic data           |
| **Write-through**      | Write to cache + DB together              | For consistency-first use cases       |
| **Write-behind**       | Write to cache, delay DB update           | For write-heavy, eventual consistency |
| **Cache-aside (Lazy)** | Load into cache only on miss              | Most common, used by Redis            |
| **Manual Invalidate**  | Explicitly purge cache on update          | For precise cache control             |

---

## ‚öñÔ∏è Cache Eviction Policies

| Policy       | Behavior                              | Use Case              |
| ------------ | ------------------------------------- | --------------------- |
| **LRU**      | Least Recently Used ‚Üí evicted first   | General purpose       |
| **LFU**      | Least Frequently Used ‚Üí evicted first | Access pattern skewed |
| **FIFO**     | First In First Out                    | Predictable rotation  |
| **TTL-only** | Expire after fixed time               | Simple TTL caches     |

**Redis Example:**

```bash
CONFIG SET maxmemory-policy allkeys-lru
```

---

## ‚ö†Ô∏è Caching Challenges

| Problem            | Description                                       | Solution                                |
| ------------------ | ------------------------------------------------- | --------------------------------------- |
| **Stale Data**     | Data in cache is outdated                         | Use TTL or manual invalidation          |
| **Cache Stampede** | Many requests trigger recomputation on cache miss | Use locks or "early recompute" strategy |
| **Cold Start**     | Cache is empty on startup                         | Warm-up with popular entries            |
| **Inconsistency**  | DB and cache out of sync                          | Use write-through or versioning         |
| **Eviction Risk**  | Popular data gets evicted                         | Use LFU policy, increase memory         |

---

## üèóÔ∏è Layered Caching Strategy

Large-scale systems often implement **multi-layer caching** for different latency tiers:

```
1. In-Memory LRU Cache (Œºs)
2. Redis / Memcached (ms)
3. CDN Cache (edge, ms)
4. Origin DB/API (slowest, 100ms+)
```

### Facebook's Memcache + DB pattern:

```
1. Try Memcache
2. If miss, fetch from DB
3. Populate Memcache
4. Serve to user
```

---

## üß© Real-World Caching Examples

| Company      | Caching Use Case                                  |
| ------------ | ------------------------------------------------- |
| **Facebook** | Uses `memcached` to cache friend lists, timelines |
| **Twitter**  | Uses Redis to cache timelines, likes, trends      |
| **Amazon**   | CDN + Redis for product pages                     |
| **Netflix**  | Client-side + edge caching for streaming          |
| **GitHub**   | In-memory caches for user/org metadata            |

---

## üìë CDN + Caching

### Static Content via Edge Caching

```txt
User ‚Üí DNS ‚Üí Cloudflare ‚Üí Cache Hit ‚Üí Serve CSS
                        ‚Ü≥ Cache Miss ‚Üí Origin S3
```

```bash
# HTTP caching headers
Cache-Control: public, max-age=86400
ETag: "abc123"
```

---

## üìê Cache Observability & Metrics

| Metric                   | What It Tells You                  |
| ------------------------ | ---------------------------------- |
| **Hit Rate (%)**         | What % of requests came from cache |
| **Eviction Count**       | How often items are removed        |
| **Latency per layer**    | Cache hit vs DB query time         |
| **Memory usage**         | Cache nearing limit?               |
| **Cold Start Frequency** | Startup issues or low TTL tuning   |

**Prometheus + Grafana** dashboards often monitor these in real-time.

---

## üîö Final Takeaways

- Caching is a **low-hanging fruit for performance**‚Äîprioritize it early.
- Use a **layered caching model**: memory ‚Üí Redis ‚Üí CDN.
- Always define a **clear invalidation + eviction strategy**.
- **Read-heavy workloads** benefit the most from caching.
- Tools like **Redis, Memcached, Cloudflare, Varnish** are industry gold standards.

---

## üß† Summary Table

| Principle       | Purpose                     | Example                               |
| --------------- | --------------------------- | ------------------------------------- |
| In-Memory Cache | Super-fast local data       | `LRU cache` in Python                 |
| Redis Cache     | Shared, fast network cache  | Store sessions, counters, objects     |
| CDN Caching     | Offload static media        | CloudFront caching images/videos      |
| TTL Expiry      | Auto-invalidates stale data | Redis `setex('key', 300, value)`      |
| LRU Policy      | Smart memory management     | Redis eviction when full              |
| Cache-aside     | Lazy loading on demand      | App loads from DB and writes to cache |

---
